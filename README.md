# Orchestration Airflow sur GCP avec Docker

---

## 1Ô∏è‚É£ Introduction

Ce projet illustre la mise en place d‚Äôun environnement **Airflow** orchestr√© via **Docker Compose** sur une **VM Google Compute Engine**.  
Il permet de g√©rer des **DAGs** pour l‚Äôingestion, le traitement et le reporting de donn√©es, tout en int√©grant un **workflow CI/CD** pour d√©ploiement automatis√©.

**Technologies utilis√©es :**  
- **Google Cloud Platform (GCP)** : Compute Engine, VPC, Firewall, PostgreSQL  
- **Docker & Docker Compose** : Conteneurisation de Airflow  
- **Git & GitHub** : Versioning et CI/CD  
- **Python & Airflow** : Orchestration des t√¢ches  

---

## 2Ô∏è‚É£ Architecture

Le sch√©ma ci-dessous montre l‚Äôarchitecture compl√®te du projet, incluant la VM, Docker Compose, Airflow Scheduler, Webserver, Postgres et les dossiers DAGs / Logs / Plugins.

![Architecture Airflow Docker GCP](/pipelines_airflow.png)  

*Auteur : Thierno BAH*

---

## 3Ô∏è‚É£ Pr√©requis

- Compte Google Cloud Platform avec projet actif  
- VM Compute Engine sous Ubuntu 22.04  
- Docker et Docker Compose install√©s  
- Git et GitHub configur√©s  
- Ports HTTP/HTTPS ouverts pour acc√©der √† Airflow Web UI (8080)

---

## 4Ô∏è‚É£ Configuration de la VM GCP

1. **Cr√©er une VM Compute Engine** :
   - Ubuntu 22.04 LTS Minimal  
   - SSD 20 GB  
   - Ouvrir HTTP/HTTPS et port TCP 8080 via Firewall  

2. **Configurer le r√©seau VPC** et les autorisations n√©cessaires pour la VM.  

3. **Cr√©er un compte de service** avec permissions :
   - `roles/editor` pour le projet (ou permissions sp√©cifiques pour Airflow et Docker)  
   - Acc√®s √† Cloud Storage et PostgreSQL  

---

## 5Ô∏è‚É£ Installation d‚ÄôAirflow avec Docker Compose

1. Cloner le projet :
```bash
git clone https://github.com/ton-utilisateur/nom-du-repo.git
cd nom-du-repo/airflow-docker
```

2. Cr√©er les dossiers Airflow :
```bash
mkdir -p dags logs plugins
```

3. Initialiser Docker Compose :
```bash
docker-compose up -d
```

4. Initialiser la base de donn√©es Airflow :
```bash
docker-compose run --rm airflow-webserver airflow db init
```

5. D√©marrer Airflow Scheduler et Webserver :
```bash
docker-compose up -d airflow-scheduler
docker-compose up -d airflow-webserver
```

6. Acc√©der √† l‚ÄôUI Airflow :  
`http://<IP_VM>:8080`  

---

## 6Ô∏è‚É£ Git & GitHub Workflow

1. Initialiser le d√©p√¥t local :
```bash
git init
```

2. Ajouter les fichiers :
```bash
git add .
```

3. Commit avec un message clair :
```bash
git commit -m "Initial commit Airflow Docker GCP"
```

4. Ajouter le d√©p√¥t distant :
```bash
git remote add origin https://github.com/ton-utilisateur/nom-du-repo.git
```

5. Envoyer les commits sur GitHub :
```bash
git push -u origin main
```

6. Pour les modifications futures :
```bash
git add .
git commit -m "Message descriptif"
git push
```

---

## 7Ô∏è‚É£ CI/CD (optionnel)

- Un trigger Cloud Build peut √™tre configur√© pour builder et d√©ployer automatiquement vos DAGs Airflow dans le conteneur Docker sur la VM √† chaque push sur `main`.  
- Permet un **d√©ploiement continu** et versionn√© de votre orchestration.

---

## 8Ô∏è‚É£ Structure du projet

```
airflow-docker/
‚îú‚îÄ dags/             # DAGs Airflow
‚îú‚îÄ logs/             # Logs des ex√©cutions
‚îú‚îÄ plugins/          # Plugins personnalis√©s
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ Dockerfile        # si n√©cessaire pour custom images
‚îî‚îÄ README.md
```

---

## 9Ô∏è‚É£ Auteurs & Contributions

- **Thierno BAH** ‚Äì Auteur et mainteneur du projet  
- Contributions possibles via pull request sur GitHub  

---

## üîó Ressources utiles

- [Documentation Airflow](https://airflow.apache.org/docs/)  
- [Docker Compose](https://docs.docker.com/compose/)  
- [Google Compute Engine](https://cloud.google.com/compute)  
- [CI/CD avec Cloud Build](https://cloud.google.com/build)

